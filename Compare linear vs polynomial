# Compare Linear vs Polynomial Regression
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Synthetic dataset
rng = np.random.RandomState(42)
X = np.linspace(-3, 3, 50).reshape(-1, 1)
y = 0.5 * X[:, 0]**3 - X[:, 0]**2 + 2 * X[:, 0] + 3 + rng.normal(0, 2, X.shape[0])

# Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_lin = lin_reg.predict(X)

# Polynomial Regression (degree=3)
poly_model = make_pipeline(PolynomialFeatures(3), LinearRegression())
poly_model.fit(X, y)
y_poly = poly_model.predict(X)

# Plot results
plt.scatter(X, y, color="black", label="Data")
plt.plot(X, y_lin, label="Linear Regression", color="blue")
plt.plot(X, y_poly, label="Polynomial Regression (deg=3)", color="red")
plt.legend()
plt.show()
